## llama1
### 先导篇
llama1 的作者提及了一个扩展法则的概念

[Chinchilla scaling laws](https://arxiv.org/pdf/2203.15556)
### Tokenizer


要点：
- 缩放法则：最优的令牌与参数比率约为2500亿令牌每10亿参数。
- 性能：在更多数据上训练的小型模型可以与在较少数据上训练的大型模型表现出相当的性能。
- 推理效率：小型模型在推理过程中可以更高效，这对于实际应用非常重要。
## llama2
对标GPT-3
Hoffmann等人 (2022) 的扩展法则的目标是确定如何在特定的训练计算预算下最佳地扩展数据集和模型的规模。
给定一个性能目标水平，理想的模型不是训练速度最快的，而是推理速度最快的。
例如，尽管Hoffmann等人 (2022) 建议在2000亿个令牌上训练100亿参数的模型，我们发现70亿参数的模型即使在1万亿个令牌之后性能仍然在持续提高。

### Tokenizer
### 模型架构

### 训练设置
#### 预训练数据
![img.png](images/img.png)
数据、超参

### 三阶段训练
#### 预训练
#### SFT
#### 对齐




